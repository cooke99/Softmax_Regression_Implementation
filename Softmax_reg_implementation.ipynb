{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load The Dataset\n",
    "\n",
    "The first step is to load the dataset we'll use to train the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "list(iris.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "print(iris['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the petal width and length are highly correlated with the target classes (the labels), we'll use these 2 features for the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris['data'][:,(2,3)] # Petal length and width\n",
    "y = iris['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split this into the training and test set now, with an 80/20 split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_init, X_test_init, y_train_init, y_test_init = train_test_split(X,y, test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute A Benchmark\n",
    "\n",
    "We'll use Scikit-learn's Softmax Regression model with regularization as a bench mark for this model, with an $\\ell_2$ penalty and $C=\\frac{1}{\\alpha}=10$. First we'll determine the training time and then compute the accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_reg = LogisticRegression(multi_class='multinomial', solver='lbfgs',C=10, penalty='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_reg.fit(X_train_init,y_train_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_reg_timed = LogisticRegression(multi_class='multinomial', solver='lbfgs',C=10, penalty='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.5 ms ± 630 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit softmax_reg_timed.fit(X_train_init,y_train_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_bench_predicts = softmax_reg.predict(X_test_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test_init,y_bench_predicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So Scikit-learn's implementation takes 9.5 ms to train and has an accuracy of approximately 100%. While I'd normally consider this to be massively overfitting the test set, in this case it has perfect accuracy due to the very small size of the dataset (test set has only 30 instances).\n",
    "\n",
    "Let's see how close we can get to these metrics using numpy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Implementation\n",
    "\n",
    "So the goal of this is to implement Batch Gradient Descent with early stopping for a Softmax Regression model without using Scikit-learn. As we're using Batch GD, the algorithm will more than likely take longer to train than Scikit-learn's implementation, however it should eventually converge to the optimal parameters. The first step is to create a training and test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a training and test set\n",
    "\n",
    "First we'll randomly shuffle the X and y indices and then use an 80/20 split for the training/test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_set(X,y, test_size=0.2):\n",
    "    # This function creates a train and test set from the data provided using the test set size ratio provided.\n",
    "    # X and y are assumed to be numpy arrays.\n",
    "    rng = np.random.RandomState(42)\n",
    "    shuffled_indices = rng.permutation(len(y))\n",
    "    split_index = np.int_(test_size*len(y))\n",
    "    train_indices = shuffled_indices[split_index:]\n",
    "    test_indices = shuffled_indices[:split_index]\n",
    "    return X[train_indices],y[train_indices], X[test_indices], y[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = split_train_test_set(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 2) (120,) (30, 2) (30,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Softmax Regression class\n",
    "\n",
    "The class needs to have 2 methods: fit and predict. Initializing the model will have 3 parameters: the penalty to apply (l2 by default), the regularization parameter alpha, and the learning rate eta.\n",
    "\n",
    "The model uses Batch Gradient Descent with early stopping to train and tune the parameters.\n",
    "\n",
    "As the model uses early stopping, the fit method will split the training data provided into a smaller training and validation set, which assumes that there was an 80/20 split for the test set. This means the ratio for the training/validation split is 75/25. A column of 1s is concatenated to the  initial training set before being split.\n",
    "\n",
    "The fit method then calls the predict method to get an array of predictions, which it then uses to compute the gradients. After each gradient descent step, the accuracy on the validation step is computed - if it is smaller than all the previous scores, it is saved. The gradient descent algorithm stops once the validation accuracy has consistently decreased for the last 100 epochs. The model paramaters are then rolled back to the last 'best' parameters. These are the parameters used for the model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxRegression():\n",
    "    def __init__(self, penalty='l2', alpha=0.1, eta0 = 0.1):\n",
    "        if not(penalty in ['l2', None]):\n",
    "            # This class will only specify an l2 regularization (half the square of the norm of the weights)\n",
    "            raise Exception('Unrecognized penalty. Only \\'l2\\' or None penalty is specified for this class.')\n",
    "        else:\n",
    "            self.penalty = penalty\n",
    "            self.alpha = alpha\n",
    "            self.eta0 = eta0\n",
    "            print('SoftmaxRegression(penalty={}, alpha={}, eta0={})'.format(penalty, alpha, eta0))\n",
    "            return None\n",
    "        \n",
    "    def fit(self, X, y, iters = 1000):\n",
    "        # The model will use Batch GD with early stopping to fit the model. Therefore the training\n",
    "        # data needs to be split into a validation set internally for early stopping.\n",
    "        # A column of 1s also needs to be appended to the set, which is carried out in function\n",
    "        # __split_train_val_set:\n",
    "        X_train,y_train, X_val, y_val = self.__split_train_val_set(X,y)        \n",
    "        self.K = len(np.unique(y_train)) # No. of classes.\n",
    "        self.n = np.size(X_train,axis=1) # No. of features.\n",
    "        self.m = np.size(X_train,axis=0) # No. of training instances.    \n",
    "        # Randomly initialize k x n array of theta values:\n",
    "        self.Theta = np.random.randn(self.K, self.n)     \n",
    "        y_train_prep, y_val_prep = self.__one_hot(y_train), self.__one_hot(y_val) # Encode labels using OneHotEncoding.     \n",
    "        if self.penalty == None:\n",
    "            # Rather than 2 large if/else blocks with much the same code (only difference being regularization term),\n",
    "            # we simply set alpha to 0 if no regularization is desired, which would set the regularization term to 0.\n",
    "            self.alpha = 0\n",
    "        # Initialise variables for GD and early stopping:\n",
    "        min_val_score = 0\n",
    "        best_theta = np.zeros_like(self.Theta)\n",
    "        gradients = np.zeros_like(self.Theta)\n",
    "        epoch_since_min = 0           \n",
    "        for epoch in range(iters):\n",
    "            if epoch_since_min >= 100:\n",
    "                # Breaks the loop if the validation error has increased for the last 100 training epochs.\n",
    "                break\n",
    "            feature_weights = np.copy(self.Theta) # Weights vector excluding bias term for regularization.\n",
    "            feature_weights[:,0] = 0\n",
    "            p_hat = self.predict(X_train,predict_proba=True, add_bias=False)\n",
    "            error = p_hat - y_train_prep\n",
    "            for i in range(self.K):\n",
    "                gradients[i,:] = error[:,i].reshape(1,-1)@X_train # Gradient sum term\n",
    "            gradients = gradients*(1/self.m) + self.alpha*feature_weights\n",
    "            self.Theta = self.Theta - self.eta0*gradients # Gradient descent step              \n",
    "            y_val_predicts = self.predict(X_val, add_bias=False) # Predictions on validation set.\n",
    "            score = self.__accuracy(y_val,y_val_predicts) # Compute accuracy on validation set.              \n",
    "            if score > min_val_score: # If the new theta values give a better accuracy on the validation set.\n",
    "                best_theta = self.Theta\n",
    "                min_val_score = score\n",
    "                epoch_since_min = 0         \n",
    "            else:\n",
    "                # Keeps count of the number of training epochs since the last best validation score was found.\n",
    "                epoch_since_min += 1\n",
    "        self.Theta = best_theta # The model parameters that gave the best accuracy on the validation set are used.\n",
    "                  \n",
    "    def predict(self,X, one_hot = False, predict_proba = False, add_bias = True):\n",
    "        # The purpose of this function is to make a prediction on an instance X using the parameters Theta. \n",
    "        # The optional argument one_hot=False returns an array of labels corresponding to the class index\n",
    "        # k i.e. for 3 classes it'll return one of [0,1,2]. If one_hot = True, it'll return a OneHot encoded\n",
    "        # version of the labels.\n",
    "        # The optional argument predict_proba allows the array of predicted probabilities (p_hat) to be\n",
    "        # returned from the function.\n",
    "        # Optional argument add_bias determines whether to concatenate a column of 1s to the X array for \n",
    "        # the bias term.\n",
    "        if one_hot and predict_proba:\n",
    "            # Both of these options can't be true as it will always return p_hat first and quit\n",
    "            # the function.\n",
    "            raise Exception('Can not return one hot encoding of labels and prediction probabilities simultaneously.')\n",
    "        else:\n",
    "            pass\n",
    "        if X.ndim == 1:\n",
    "            # In case a single instance is passed to the function.\n",
    "            X = X.reshape(1,-1)\n",
    "        else:\n",
    "            pass\n",
    "        if add_bias:\n",
    "            X_prep = np.c_[np.ones((np.size(X,axis=0),1)),X]\n",
    "        else:\n",
    "            X_prep = X\n",
    "        softmax_score = X_prep.dot(self.Theta.T)\n",
    "        exponents = np.exp(softmax_score)\n",
    "        p_hat = np.divide(exponents, np.sum(exponents, axis=1).reshape(-1,1))        \n",
    "        if predict_proba:\n",
    "            return p_hat\n",
    "        else:    \n",
    "            predictions = np.argmax(p_hat,axis=1)\n",
    "            if one_hot:\n",
    "                return self.__one_hot(predictions.ravel())       \n",
    "            else:\n",
    "                return predictions.ravel()\n",
    "        \n",
    "    def __split_train_val_set(self, X, y, val_size=0.25):\n",
    "        # This is a private method that creates a train and validation set from \n",
    "        # the data provided using a 75/25 split. X and y are assumed to be numpy arrays.\n",
    "        X_prep = np.c_[np.ones((np.size(X,axis=0),1)),X] # Concatenate bias term to data.\n",
    "        shuffled_indices = np.random.permutation(len(y))\n",
    "        split_index = np.int_(val_size*len(y))\n",
    "        train_indices = shuffled_indices[split_index:]\n",
    "        val_indices = shuffled_indices[:split_index]   \n",
    "        return X_prep[train_indices],y[train_indices], X_prep[val_indices], y[val_indices]\n",
    "    \n",
    "    def __one_hot(self,labels):\n",
    "        # This private method is a custom implementation for OneHotEncoder that will convert the labels array\n",
    "        # of k values (class indexes) into a one hot encoded matrix.\n",
    "        encoded = np.zeros((len(labels),self.K))\n",
    "        encoded[np.arange(len(labels)), labels] = 1\n",
    "        return encoded\n",
    "    \n",
    "    def __accuracy(self,labels,predictions):\n",
    "        # Computes the accuracy to evaluate generalization score on validation set.\n",
    "        if labels.shape != predictions.shape:\n",
    "            raise Exception('Error: Label and prediction dimensions do not match')\n",
    "        else:\n",
    "            correct = np.sum(labels==predictions,axis=0)\n",
    "            return correct/(np.size(labels,axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does it perform?\n",
    "\n",
    "Now that the SoftmaxRegression class is finished, how does it perform compared to Scikit-learn's version?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SoftmaxRegression(penalty=None, alpha=0.1, eta0=0.1)\n"
     ]
    }
   ],
   "source": [
    "soft_reg = SoftmaxRegression(penalty=None) # No regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(labels,predictions):\n",
    "    correct = np.sum(labels==predictions,axis=0)\n",
    "    return correct/(np.size(labels,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = soft_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y_test,test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SoftmaxRegression(penalty=l2, alpha=0.1, eta0=0.1)\n"
     ]
    }
   ],
   "source": [
    "soft_reg_l2 = SoftmaxRegression() # With l2 regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_reg_l2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions_l2 = soft_reg_l2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y_test,test_predictions_l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the time taken to train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SoftmaxRegression(penalty=l2, alpha=0.1, eta0=0.1)\n"
     ]
    }
   ],
   "source": [
    "timed_clf = SoftmaxRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.6 ms ± 4.73 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit timed_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, this implementation takes twice as long as Scikit-learn's. Not bad considering there is no optimization done and it's all written in Python.\n",
    "\n",
    "From running the code multiple times, it's hard to effectively determine the performance of the classifier with such a small dataset. The runtime varies from 12 ms to 23 ms, with the accuracy on the test set varying anywhere from 30% to 97%. A larger dataset is needed to determine a more consistent performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance on MNIST dataset\n",
    "\n",
    "Fortunately, the MNIST dataset is much larger and should give a much better estimate of the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784', version=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mn, y_mn = mnist['data'], mnist['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mn = y_mn.astype(int) # Labels are strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mn, y_train_mn, X_test_mn, y_test_mn = split_train_test_set(X_mn,y_mn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to scale the features of the dataset before training. For convenience I'm going to cheat and use sklearn's StandardScaler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mn = scaler.fit_transform(X_train_mn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_mn = scaler.transform(X_test_mn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SoftmaxRegression(penalty=l2, alpha=0.1, eta0=0.1)\n"
     ]
    }
   ],
   "source": [
    "mnist_clf = SoftmaxRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_clf.fit(X_train_mn[:10000], y_train_mn[:10000], iters=2000) # 2000 iterations due to the size of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mnist_clf.predict(X_test_mn[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.896"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y_test_mn[:2000],predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "89.6% accuracy. Not bad. What about Scikit-learn's model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_clf_skl = LogisticRegression(multi_class='multinomial', solver='lbfgs',C=10, penalty='l2', max_iter = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=2000,\n",
       "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_clf_skl.fit(X_train_mn[:10000], y_train_mn[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "skl_predictions = mnist_clf_skl.predict(X_test_mn[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.876"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y_test_mn[:2000], skl_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, Scikit-learn's model actually performs worse (by 2%). I'll take that as a win."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
